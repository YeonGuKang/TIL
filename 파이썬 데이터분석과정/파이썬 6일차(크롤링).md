# 6일차 - 웹 크롤링의 기초에 대해서

1. 크롤링이란?\
크롤러(crawler)는 자동화된 방법으로 웹을 탐색하는 컴퓨터 프로그램

'웹 크롤링'(web crawling)??

'데이터 크롤링'(data crawling)!!

웹 크롤링을 위해 BeautifulSoup 사용\
requests는 요청을 받기는 하지만 text로만 받음\
API는 통신을 위해 정형화 된 데이터 형태의 text\
우리가 원하는 데이터로 가공하기 위해 편의상 html로 변환\
text를 html로 변환하는 모듈이 beautifulSoup !!! 아주중요!

### 필요패키지 import
import numpy as np\
import pandas as pd\
import requests # 크롤링에 사용하는 패키지\
from bs4 import BeautifulSoup # html 변환에 사용함

### url정의
url = 'https://www.naver.com/'

### requsts로 url에 정보요청
response = requests.get(url).text

### 정보를 html 변환 (보기 쉽게)
html = BeautifulSoup(response, 'html.parser')

### html 내에서 우리가 보고 싶은 정보만 선별
html.select('img')

가져온 html에서 img태그만 뽑아와서 출력을 한다.\
원하는 tag에서 더 세세하게 뽑아오기 위해 셀렉터를 이용해야하는데\
그 셀렉터를 가져올 때 규칙들이다.

셀렉터\
용도 : html에서 내가 원하는 내용을 찾아내기 위해서\

```
<span class="news" id="1234">비비고 왕교자</span>
```

단일 셀렉터

html.select('span')\
tag : span\
class(별명, 그룹명) : .news\
>>> id(고유값) : #1234

또한 html의 구조가 단편적이지 않기 때문에 \
복합 셀렉터를 이용하여 더 세세하게 정보를 가져올 수 있다.

복합 셀렉터\
1. 조합 셀렉터\
```
<span>1</span>
<span class="txt">2</span>
<em class="txt">3</em>
```

태그 이름이 span이고 클래스 이름은 txt인 라인을 찾고 싶다. : span.txt \
li 태그 중에서 id가 name 인 라인을 찾고 싶다. : li#name

2. 경로 셀렉터\
```
<ul>
    <li><span>이걸 찾으려면?</span></li>
</ul>
<span>이건 아님</span>
```

ul 태그안 li 태그 안 span 라인을 찾는다\
ul > li > span 혹은 ul li span

requests의 현재 code를 보고 상태를 파악할 수 있다.

requests.codes.ok\
### 100 우리 이런정보 내주는거야
### 200 성공
### 300 우리 이 사이트 이리루 이사했어 일루가
### 400 유저가 요청을 잘못한경우
### 500 서버 문제

아래는 위의 정보들을 이용하여 받은 키워드를 네이버에서 검색해\
블로그 제목을 가져오는 코드이다.

key_word = input('키워드를 입력하세요 :')\
url = f'https://search.naver.com/search.naver?where=view&sm=tab_jum&query={key_word}'

response = requests.get(url)

if response.status_code == requests.codes.ok:\
    print('접속성공')

html = BeautifulSoup(response.text, 'html.parser')

titles = html.select('a.api_txt_lines')\
for title in titles:\
    print(title.text, title.attrs['href'])


4. 동적페이지 크롤링\
최근에는 Js로 변경이 되며 일반적인 크롤링이 되지 않는 경우가 많음\
동적페이지와 숨겨진 url을 가져오는 방법을 알아봅니다

import json

### 카테고리 데이터 가져오기
url = 'https://datalab.naver.com/shoppingInsight/getKeywordRank.naver?timeUnit=date&cid=50000000'

### 헤더정보 필요
header = {\
    'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.96 Safari/537.36',\
    'referer': 'https://datalab.naver.com/'\
}

response = requests.post(url, headers=header)\
data = json.loads(response.text)\
data

저 헤더정보가 핵심인데 꼭 network에서 뽑아서 넣어주어야한다.\
저게 없으면 json이 동작하지 않으니 꼭 유의할것.

또한 json으로 가져온 것은 아래처럼 key값을 이용하여 손쉽게 key값\
속에 있는 데이터들을 df로 만들 수 있다.\
단 그 key값안에 dict들이 있어야 하며 그 dict의 key가 컬럼이 되며\
각각의 value들이 로우가 된다.

df = pd.DataFrame(data['data'])
