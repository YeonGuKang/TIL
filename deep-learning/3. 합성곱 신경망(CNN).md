# 합성곱 신경망(CNN)-
1차원으로 변환된 결과는 사람이 보기에도 이게 원래 어떤 이미지였는지 알아보기가 어렵습니다.(완전연결계층 - Affine)\
 이는 기계도 마찬가지 입니다. 위와 같이 결과는 변환 전에 가지고 있던 공간적인 구조(spatial structure) 정보가 유실된 상태입니다. \
여기서 공간적인 구조 정보라는 것은 거리가 가까운 어떤 픽셀들끼리는 어떤 연관이 있고, 어떤 픽셀들끼리는 값이 비슷하거나 등을 포함하고 있습니다.\
 결국 이미지의 공간적인 구조 정보를 보존하면서 학습할 수 있는 방법이 필요해졌고, 이를 위해 사용하는 것이 합성곱 신경망입니다.

CNN 은 3차원 정보 데이터를 conv와 relu 그리고 pooling을 이용하여서 중요한 특징들을 뽑아\
다시 2차원 정보로 만든 뒤에 그 정보를 앞에서 배운 softmax와 cross entropy로 확인하는 것이다.

우리가 사용하던 완전연결 신경망은 데이터의 형상이 무시된다는 문제점이 존재했다.\
MNIST로 예를들면 우리는 28X28 의 픽셀값을 한줄로 쫙 나열해서 1X28X28로 사용였다.\
이는 공간의 차원을 무시하게 된다. 따라서 공간적 정보를 담기 위해 CNN을 사용한다.\
예를 들면 이미지의 경우에는 세로 X 가로 X 채널(색상)으로 색상이라는 공간적 정보가 중요하다.\
CNN의 필터(커널)의 매개변수가 우리가 그동안에 사용하던 가중치이다!

패딩 - 데이터 주변을 일정값으로 채움 : 주로 출력크기가 줄어드는 문제를 해결하기 위해서 사용한다.\
(그냥 CNN을 사용하면 입력에 비해 출력이 크기가 줄어들기 때문)\
스트라이드 - 필터를 적용하는 위치의 간격

 합성곱 연산을 수행할 때, \
입력 데이터의 채널 수와 필터의 채널수가 같아야 한다.\
즉 필터의 채널은 이미지의 RGB ! 합성곱 연산은 출력의 shape(?by?)를 결정!\
이 shape를 계산할 때에 입력데이터의 채널 수와 필터(RGB)의 채널수가 같아야 한다!

nn.Conv2d(3, 32, 3, padding=1)\
첫번째 parameter 인 3은 input_channel_size가 되겠습니다. \
여기서 input_channel_size는 Input Image의 RGB depth 인 3이 되겠습니다.\
(RGB 는 여기서 필터의 채널 수 -> 입력 채널수와 필터의 채널수가 같다!)

두번째 parameter 인 32는 output_channel_size입니다. \
즉, conv1 layer를 거쳐 몇장의 필터를 만들어 내고 싶은가? 입니다. \
32장의 필터를 만들어 내고 싶으므로, 32가 되겠습니다.\
즉 우리가 RGB를 어떻게 조합해서 서로 다른 필터 32개를 만들어 내고,\
이는 이 필터들을 통과하는 출력 32장이 나온다는 소리다.\
RGB 필터 채널을 묶어서 새로운것을 몇개 만들것이냐 ? 32개를 만들것이다!


https://excelsior-cjh.tistory.com/180
